{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7dd42e-ad7c-4691-9323-58f3022c34e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective - \n",
    "Create generation on a model for human eval data, evaluate the generations and write them to a file\n",
    "\"\"\"\n",
    "\n",
    "model_path = \"Meta-Llama-3-8B-Instruct-oss-full-2e-4bs\" # local path/s3 name/huggingface name of model\n",
    "model_name = \"Meta-Llama-3-8B-Instruct-oss-full-2e-4bs\" # model name (DONT keep any '/' or '.' in there)\n",
    "tokeniser = None # huggingface name/local path of tokeniser, make it None if model already has tokeniser\n",
    "isS3 = True # true if model is to be loaded from s3, make sure ./model directory is empty\n",
    "isHF = False  # true if model is to be loaded from huggingface\n",
    "isLocal = False # true if model is to be loaded from local\n",
    "benchmark='humaneval' #choose from [\"humaneval\", \"mbpp\"]\n",
    "home_path = '/home/ec2-user/SageMaker'   # local path starting from root to CodeLLMRnD\n",
    "\n",
    "run_generations = True # make it false if you only want to evaluate\n",
    "greedy = True # evalplus -> greedy True, if want to give custom n_samples, temperature, max_length_generation, top_p, pass greety=True\n",
    "n_samples = 50 # evalplus -> n_samples=1, bigcode -> n_samples=50\n",
    "temperature = 0.2 # evalplus -> temperature=0, bigcode -> temperature=0.2\n",
    "\n",
    "merged_results_file_name= \"evalplusrepo_\"+benchmark+\"_results_\"+model_name+\".jsonl\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4fee2a-8c12-446a-abb9-55f08cff9d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -e .\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q -r codegen/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62e946-d3db-4cf1-a3d9-027d6cef3d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_results_dir = benchmark + \"_inference/\" # local path to save results - end the path with a \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15336d4-cf9d-4dd0-8b4e-a1815115ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../human_eval')\n",
    "from run_bash_command import run_bash_command\n",
    "if not isLocal and run_generations:\n",
    "    run_bash_command(f\"sudo find {home_path} -type f -size +500M -print0 | xargs -0 rm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d12741-2ed8-4e89-b33a-c2bfd4c313c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "if os.path.isdir(inference_results_dir) and run_generations:\n",
    "    shutil.rmtree(inference_results_dir)\n",
    "os.makedirs(os.path.dirname(inference_results_dir), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df64458-d999-4b0c-929e-1eab1f9ef253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if isS3:\n",
    "    sys.path.append('../fine_tuning/utils')\n",
    "    from modelComm import ModelComm\n",
    "    modelComm = ModelComm()\n",
    "    model_path = modelComm.download_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972265d-3ccf-40a8-bf44-928ca5695c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "local = (isHF==False)\n",
    "if greedy:\n",
    "    command = f\"python codegen/generate.py --model {model_path} --bs 1 --greedy --root {inference_results_dir} --dataset {benchmark}\"\n",
    "else:\n",
    "    command = f\"python codegen/generate.py --model {model_path} --bs 1 --temperature {temperature} --n_samples {n_samples} --root {inference_results_dir} --dataset {benchmark}\"\n",
    "\n",
    "if local:\n",
    "    command += \" --local\"\n",
    "print(command)\n",
    "if run_generations:\n",
    "    run_bash_command(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5955b1b-8e3a-4913-bbec-715d77e0ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if greedy:\n",
    "    temperature=0.0\n",
    "command = f\"evalplus.evaluate --dataset {benchmark} --samples {inference_results_dir}{benchmark}/{model_path}_temp_{temperature}/ --i-just-wanna-run\"\n",
    "print(command)\n",
    "run_bash_command(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360e7c3-ff06-4b1c-86a8-cb0d20f69b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if benchmark == \"mbpp\":\n",
    "    test_file = os.path.join('data','MbppPlus-v0.1.0.jsonl')\n",
    "else:\n",
    "    test_file = os.path.join('data','HumanEvalPlus-v0.1.9.jsonl')\n",
    "command = f\"python merge_results.py {inference_results_dir}{benchmark}/{model_path}_temp_0.0/eval_results.json {test_file} {inference_results_dir}\"\n",
    "print(command)\n",
    "run_bash_command(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb82704-8e1d-44f4-8f92-90494a815db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results_path = os.path.join(inference_results_dir,'final_results.jsonl')\n",
    "import sys; sys.path.append(home_path+'/CodeLLMRnD/fine_tuning/utils')\n",
    "from resultsComm import ResultsComm\n",
    "resultsComm = ResultsComm()\n",
    "resultsComm.upload_results(merged_results_path, merged_results_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
